
---

# ðŸ“¦ InstaCart Retail Data Warehouse & Analytics Engineering Pipeline

**Built from scratch: PostgreSQL, SQL, dbt, and Power BI (DirectQuery on 3M+ rows).**

---

## ðŸš€ Project Purpose

To design and deliver a production-style retail analytics warehouse and BI pipeline, implementing all layers (raw â†’ staging â†’ marts) in PostgreSQL, modeling transformations in dbt, and serving live dashboards via Power BI DirectQuery.

---

## ðŸ—ï¸ Architecture Overview

![pipeline](images/architecture.png)

---

## ðŸ“Š Dataset

This project uses the public [Instacart Online Gorcery Analysis Dataset](https://www.kaggle.com/datasets/yasserh/instacart-online-grocery-basket-analysis-dataset)  dataset from Kaggle (3M+ rows of orders, products, and baskets).

---

## ðŸ› ï¸ Tech Stack

* **Python**: Data loading and preprocessing
* **Python packages**: pandas,sqlalchemy,os
* **PostgreSQL**: Data warehouse, schemas, indexing, materialized views,
* **SQL**: Transformation logic, KPI calculations.
* **dbt Core**: Staging, intermediate, and mart models
* **Power BI**: DirectQuery dashboards on 3M+ rows
* **Git**: Version control (~50 commits)
* **Npgsql (.NET PostgreSQL Driver)**: for reliable and high-performance connection between PostgreSQL and Power BI, allowing to use DirectQuery for live dashboards 


---

## ðŸ—„ï¸ 1. Data Warehouse Design

Engineered a complete warehouse architecture in PostgreSQL with raw, staging, intermediate, and mart layers.
Manually designed schemas, implemented primary/foreign keys, and created materialized views for performance.

![Schema](images/schema.png)
![views and mvs](images/views_and_mvs.png)

---

## ðŸ”„ 2. SQL Transformations & Optimization

All transformation and metric logic was implemented in SQL at the database level to ensure correctness, performance, and reuse across downstream layers. Performance was optimized using indexing and materialized views before introducing dbt for transformation modeling.

---

## ðŸ§± 3. dbt Modeling (Exploration and Documentation layer)

After validating core SQL logic at the database level, selected transformations were replicated and modeled in dbt to learn dbt workflows, layering patterns (staging â†’ intermediate â†’ marts), and lineage generation. The primary BI layer continued to consume optimized database views and materialized views via DirectQuery. Additional details are documented in dbt/README.md.

![dbt lineage graph](images/dbt_graph.png)

---

## ðŸ“Š 4. Power BI Dashboard (DirectQuery)

The dashboard consumes only prepared PostgreSQL views, avoiding complex DAX and keeping BI logic minimal. A 3-page Power BI dashboard is connected live via DirectQuery to handle 3M+ rows in real time.

![dashboard_pg_1](dashboards/dashboard_1.png)
![dashboard_pg_2](dashboards/dashboard_2.png)
![dashboard_pg_3](dashboards/dashboard_3.png)

---

## ðŸ“‚ Repository Structure

```text
Retail_Analytics_Engineering_Pipeline/
â”œâ”€â”€ dashboards/
â”‚   â”œâ”€â”€ dashboard.pbix
â”‚   â”œâ”€â”€ dashboard.pdf
â”‚   â”œâ”€â”€ dashboard_1.png
â”‚   â”œâ”€â”€ dashboard_2.png
â”‚   â””â”€â”€ dashboard_3.png
â”‚
â”œâ”€â”€ data_raw/
â”‚   â”œâ”€â”€ aisles.csv
â”‚   â”œâ”€â”€ departments.csv
â”‚   â”œâ”€â”€ orders.csv
â”‚   â”œâ”€â”€ order_products__prior.csv
â”‚   â”œâ”€â”€ order_products__train.csv
â”‚   â””â”€â”€ products.csv
â”‚
â”œâ”€â”€ data_clean/
â”‚   â”œâ”€â”€ aisles.csv
â”‚   â”œâ”€â”€ departments.csv
â”‚   â”œâ”€â”€ orders.csv
â”‚   â”œâ”€â”€ order_products.csv
â”‚   â””â”€â”€ products.csv
â”‚
â”œâ”€â”€ dbt/
â”‚   â”œâ”€â”€ dbt_project.yml
â”‚   â”œâ”€â”€ profiles.yml
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ staging/
â”‚   â”‚   â”‚   â”œâ”€â”€ stg_aisles.sql
â”‚   â”‚   â”‚   â”œâ”€â”€ stg_departments.sql
â”‚   â”‚   â”‚   â”œâ”€â”€ stg_orders.sql
â”‚   â”‚   â”‚   â”œâ”€â”€ stg_order_products.sql
â”‚   â”‚   â”‚   â””â”€â”€ stg_products.sql
â”‚   â”‚   â”œâ”€â”€ intermediate/
â”‚   â”‚   â”‚   â””â”€â”€ int_order_basket_sizes.sql
â”‚   â”‚   â””â”€â”€ mart/
â”‚   â”‚       â”œâ”€â”€ agg_orders_by_dow.sql
â”‚   â”‚       â”œâ”€â”€ agg_product_metrics.sql
â”‚   â”‚       â”œâ”€â”€ fct_kpi_overview.sql
â”‚   â”‚       â””â”€â”€ fct_orders_by_dow.sql
â”‚   â””â”€â”€ sources.yml
â”‚
â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ architecture.png
â”‚   â”œâ”€â”€ dbt_graph.png
â”‚   â”œâ”€â”€ schema.png
â”‚   â””â”€â”€ views_and_mvs.png
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_explore_raw.ipynb
â”‚   â”œâ”€â”€ 02_clean_transform.ipynb
â”‚   â””â”€â”€ 03_load_to_postgres.ipynb
â”‚
â”œâ”€â”€ sql/
â”‚   â”œâ”€â”€ 01_schema.sql
â”‚   â”œâ”€â”€ 02_test_load.sql
â”‚   â”œâ”€â”€ 03_indexes.sql
â”‚   â”œâ”€â”€ 04_analytics_queries.sql
â”‚   â”œâ”€â”€ 05_views.sql
â”‚   â”œâ”€â”€ 06_materialized_views.sql
â”‚   â””â”€â”€ 07_metric_views.sql
â”‚
â””â”€â”€ ETL_RUN_LOG.md
```

______________________________________________
---

## ðŸ“ How to Run Locally


1. Clone the repository and set up the Python environment.
2. Run the ETL notebooks to load and clean the raw Instacart data into PostgreSQL.
3. Execute the SQL scripts under `sql/` (schemas, indexes, views, and materialized views) to prepare the analytics layer.
4. Open Power BI and connect to PostgreSQL via DirectQuery to the prepared views.

> Note: dbt models in this repository were developed to replicate and document selected transformations and generate lineage. The Power BI dashboard consumes optimized PostgreSQL views and materialized views directly.

---

## ðŸ”§ Future Improvements

* Expand dbt coverage to fully productionize transformations currently implemented as database views
* Add dbt tests (uniqueness, relationships)
* Deploy dbt using a scheduler such as Airflow
* Introduce incremental models for larger-scale datasets

---

## ðŸ‘¤ Author

Raga, Junior Analytics Engineer | Berlin, Germany

---
